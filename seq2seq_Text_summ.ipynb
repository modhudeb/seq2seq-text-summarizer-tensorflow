{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1lXKE-E8um6xHo2lU6T5uNAvDoiarU0Qr",
      "authorship_tag": "ABX9TyNXTqX0g78TzppmKaINuGl5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/modhudeb/seq2seq-text-summarizer-tensorflow/blob/main/seq2seq_Text_summ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "QIpjXVJG-Me9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBghnz1p-D_O"
      },
      "outputs": [],
      "source": [
        "# from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "DOpI2qZVQxAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import contractions"
      ],
      "metadata": {
        "id": "jjydNnBH-QnT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "IUb1TSw_-XcM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V0ZcnUJy-XUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading data"
      ],
      "metadata": {
        "id": "6OB9y4FA-X2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with ZipFile(\"/content/drive/MyDrive/data/Text_summarize/AmazonReviewSumma.zip\") as zf:\n",
        "#   zf.extractall(\"/content/drive/MyDrive/data/Text_summarize/\")"
      ],
      "metadata": {
        "id": "JzfsEQPb-1uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/data/Text_summarize/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS-kcWoz_Q8q",
        "outputId": "1d958cee-b72c-4240-caf1-318c9070ed97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glove.6B.100d.txt', 'Reviews.csv', 'text_summ_model.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/data/Text_summarize/Reviews.csv\")"
      ],
      "metadata": {
        "id": "fu5RTMAD_XJ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQnNxVzH_yYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "78qW-hhM_zfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B1gIa0zGo6k",
        "outputId": "9fd526eb-41b8-40c1-ab3e-6e134c71dfb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                         0\n",
              "ProductId                  0\n",
              "UserId                     0\n",
              "ProfileName               16\n",
              "HelpfulnessNumerator       0\n",
              "HelpfulnessDenominator     0\n",
              "Score                      0\n",
              "Time                       0\n",
              "Summary                   27\n",
              "Text                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Summary'], inplace = True)"
      ],
      "metadata": {
        "id": "IbPokoHJGo3P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['Text', 'Summary']]"
      ],
      "metadata": {
        "id": "4yzaDIlGGozy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "5D4K3bUJGowg",
        "outputId": "f86a3dad-d0e0-42ae-94ad-bff73a282bc7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "568427\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text                Summary\n",
              "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
              "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80b71400-1705-4e53-8796-caf525ca178f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>Not as Advertised</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b71400-1705-4e53-8796-caf525ca178f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80b71400-1705-4e53-8796-caf525ca178f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80b71400-1705-4e53-8796-caf525ca178f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b828bc2-7b73-4bb7-9a60-dbd043775fd0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b828bc2-7b73-4bb7-9a60-dbd043775fd0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b828bc2-7b73-4bb7-9a60-dbd043775fd0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't need all of it. We will take short length texts only"
      ],
      "metadata": {
        "id": "81aj-FPjI3B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[(df['Text'].apply(lambda x:len(x))<201) & (df['Text'].apply(lambda x:len(x))>150)]\n",
        "df.reset_index(drop = True, inplace=True)\n",
        "df = df[(df['Summary'].apply(lambda x:len(x))<100) & (df['Summary'].apply(lambda x:len(x))>20)]\n",
        "df.reset_index(drop = True, inplace=True)"
      ],
      "metadata": {
        "id": "VIWAOeZoGop3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)   # Now we have this 27726 samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smZCWNgVJz0G",
        "outputId": "32376ab9-4419-4a86-9234-e467281105dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27726"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to clean our TEXTs"
      ],
      "metadata": {
        "id": "L2ARm_9TSUrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'][15000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "s_LFJIfxTK3Q",
        "outputId": "acb4a9f2-b36d-4bb3-c503-e3ae1842214d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Easy to make & good tasting flavor.<br />The price is  high but you get what you pay for.<br />Hope the Cherrybrook kitchen company doesn't raise the<br />price...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  \"\"\"Cleans text by removing extra full stops, punctuations, extra white spaces and html tags.\"\"\"\n",
        "\n",
        "  # Remove extra full stops.\n",
        "  text = re.sub(r'\\.+', '.', text)\n",
        "\n",
        "  # Remove html tags.\n",
        "  text = re.sub(r'<[^>]*>', '', text)\n",
        "\n",
        "  # Fixing aporstrophes\n",
        "  text = contractions.fix(text)\n",
        "\n",
        "  # Remove other punctuations\n",
        "  text = re.sub(r'[^\\w\\s]+', ' ', text)\n",
        "\n",
        "  # Remove extra white spaces.\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "  return text.lower()\n",
        "\n",
        "\n",
        "\n",
        "df['Text'] = df['Text'].apply(clean_text)\n",
        "df['Summary'] = df['Summary'].apply(clean_text)"
      ],
      "metadata": {
        "id": "jh8oWyuGJzts"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'][15000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oI5Rzbw3ThKg",
        "outputId": "a9b531b2-2a98-467a-9fdf-118954ff4f6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'easy to make good tasting flavor the price is high but you get what you pay for hope the cherrybrook kitchen company does not raise theprice '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to get the TEXTS tokenized and index numbers of them. So we will preprocess the texts now..."
      ],
      "metadata": {
        "id": "MKmQJqTvPxl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define max sequence lengths for both text and summary\n",
        "max_text_length = max(df['Text'].apply(lambda x : len(x.split())))\n",
        "max_summary_length = max(df['Summary'].apply(lambda x : len(x.split())))\n",
        "\n",
        "\n",
        "print(\"Text Max len: \",max_text_length, \"\\nSummary Max len: \",max_summary_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9vqGvZw1r2d",
        "outputId": "15106143-9c08-44b0-bb3a-3c1c3fff94de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Max len:  50 \n",
            "Summary Max len:  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Dec_Summary'] = df['Summary'].apply(lambda x : \"<sos> \"+ x +\" <eos>\")\n",
        "# Tokenize and pad sequences for Text\n",
        "text_tokenizer = Tokenizer()\n",
        "text_tokenizer.fit_on_texts(df['Text'])\n",
        "text_sequences = text_tokenizer.texts_to_sequences(df['Text'])\n",
        "text_sequences = pad_sequences(text_sequences, maxlen=max_text_length, padding='post')\n",
        "\n",
        "# Tokenize and pad sequences for Summary\n",
        "summary_tokenizer = Tokenizer()\n",
        "summary_tokenizer.fit_on_texts(df['Dec_Summary'])\n",
        "summary_sequences = summary_tokenizer.texts_to_sequences(df['Dec_Summary'])\n",
        "summary_sequences = pad_sequences(summary_sequences, maxlen=max_summary_length, value=summary_tokenizer.word_index['eos'], padding='post')\n",
        "summary_sequences_out = summary_tokenizer.texts_to_sequences(df['Summary'])\n",
        "summary_sequences_out = pad_sequences(summary_sequences_out, maxlen=max_summary_length, value=summary_tokenizer.word_index['eos'], padding='post')\n",
        "\n",
        "\n",
        "\n",
        "# Define vocabulary sizes\n",
        "vocab_size_text = len(text_tokenizer.word_index) + 1\n",
        "vocab_size_summary = len(summary_tokenizer.word_index)+1\n"
      ],
      "metadata": {
        "id": "4AtBHiMBPxHs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text vocab size: \",vocab_size_text, \"\\nSummary vocab size: \",vocab_size_summary)"
      ],
      "metadata": {
        "id": "cMwbcdDgPxEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66285ba0-3c8f-44d9-ef3c-65b155d47fdc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text vocab size:  16946 \n",
            "Summary vocab size:  8408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yd6a-6Yj5pn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "su79EWLR5pc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will fetch GloVe vectors for the each vocabulary..."
      ],
      "metadata": {
        "id": "rN5-3MSf3tpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading GloVe embeddings\n",
        "glove_path = \"/content/drive/MyDrive/data/Text_summarize/glove.6B.100d.txt\"\n",
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_text, embedding_dim))\n",
        "\n",
        "with open(glove_path, 'r', encoding='utf-8') as glove_file:\n",
        "    for line in glove_file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        if word in text_tokenizer.word_index:\n",
        "            idx = text_tokenizer.word_index[word]\n",
        "            embedding_matrix[idx] = np.array(values[1:], dtype='float32')"
      ],
      "metadata": {
        "id": "TkHkRwmO_0ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vA9I3lsLDPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YiRssE8E5DN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RSZZc7V68IAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENCODER-DECODER architecture"
      ],
      "metadata": {
        "id": "k4VemZyS8ju3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(shape=(max_text_length,))\n",
        "encoder_embedding = layers.Embedding(input_dim=vocab_size_text, output_dim=embedding_dim,\n",
        "                              weights=[embedding_matrix], trainable=False)(encoder_input)\n",
        "encoder_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(max_summary_length,))\n",
        "decoder_embedding = layers.Embedding(input_dim=vocab_size_summary, output_dim=embedding_dim)(decoder_input)\n",
        "decoder_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention Mechanism\n",
        "attention_layer = layers.Attention()([decoder_outputs, encoder_outputs])\n",
        "decoder_combined = layers.Concatenate(axis=-1)([decoder_outputs, attention_layer])\n",
        "\n",
        "# Dense layer for prediction\n",
        "decoder_dense = layers.Dense(vocab_size_summary, activation='softmax')\n",
        "output = decoder_dense(decoder_combined)\n",
        "\n",
        "\n",
        "model = Model([encoder_input, decoder_input], output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ZnOtx4228H4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are using the `sparse_categorical_crossentropy`. Because if we use ***categorical_crossentropy*** we need to have <b>one-hot encoded sequence</b>.\n",
        "\n",
        "But the one-hot sequence requires high config system while training."
      ],
      "metadata": {
        "id": "slR45R5jWavD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VEtrRxUh61t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([text_sequences, summary_sequences], summary_sequences_out, epochs=20, batch_size=16, validation_split=0.2)"
      ],
      "metadata": {
        "id": "IWWG_BhVCuIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c207ba-0836-48d9-bb26-e32a2e115019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1387/1387 [==============================] - 37s 24ms/step - loss: 1.8051 - accuracy: 0.7497 - val_loss: 1.6492 - val_accuracy: 0.7576\n",
            "Epoch 2/20\n",
            "1387/1387 [==============================] - 24s 18ms/step - loss: 1.4707 - accuracy: 0.7720 - val_loss: 1.4213 - val_accuracy: 0.7793\n",
            "Epoch 3/20\n",
            "1387/1387 [==============================] - 24s 18ms/step - loss: 1.2249 - accuracy: 0.7937 - val_loss: 1.2879 - val_accuracy: 0.7965\n",
            "Epoch 4/20\n",
            "1387/1387 [==============================] - 24s 17ms/step - loss: 1.0256 - accuracy: 0.8155 - val_loss: 1.2100 - val_accuracy: 0.8129\n",
            "Epoch 5/20\n",
            "1387/1387 [==============================] - 25s 18ms/step - loss: 0.8576 - accuracy: 0.8360 - val_loss: 1.1658 - val_accuracy: 0.8247\n",
            "Epoch 6/20\n",
            "1387/1387 [==============================] - 24s 17ms/step - loss: 0.7163 - accuracy: 0.8568 - val_loss: 1.1522 - val_accuracy: 0.8328\n",
            "Epoch 7/20\n",
            "1387/1387 [==============================] - 24s 17ms/step - loss: 0.6018 - accuracy: 0.8762 - val_loss: 1.1543 - val_accuracy: 0.8385\n",
            "Epoch 8/20\n",
            "1387/1387 [==============================] - 23s 16ms/step - loss: 0.5114 - accuracy: 0.8918 - val_loss: 1.1549 - val_accuracy: 0.8428\n",
            "Epoch 9/20\n",
            "1387/1387 [==============================] - 24s 17ms/step - loss: 0.4376 - accuracy: 0.9058 - val_loss: 1.1669 - val_accuracy: 0.8470\n",
            "Epoch 10/20\n",
            "1387/1387 [==============================] - 23s 17ms/step - loss: 0.3774 - accuracy: 0.9174 - val_loss: 1.1887 - val_accuracy: 0.8481\n",
            "Epoch 11/20\n",
            "1387/1387 [==============================] - 23s 16ms/step - loss: 0.3256 - accuracy: 0.9277 - val_loss: 1.2092 - val_accuracy: 0.8500\n",
            "Epoch 12/20\n",
            "1387/1387 [==============================] - 23s 17ms/step - loss: 0.2822 - accuracy: 0.9372 - val_loss: 1.2328 - val_accuracy: 0.8511\n",
            "Epoch 13/20\n",
            "1387/1387 [==============================] - 25s 18ms/step - loss: 0.2447 - accuracy: 0.9450 - val_loss: 1.2616 - val_accuracy: 0.8512\n",
            "Epoch 14/20\n",
            "1387/1387 [==============================] - 24s 17ms/step - loss: 0.2133 - accuracy: 0.9519 - val_loss: 1.2830 - val_accuracy: 0.8526\n",
            "Epoch 15/20\n",
            "1387/1387 [==============================] - 26s 19ms/step - loss: 0.1854 - accuracy: 0.9581 - val_loss: 1.3113 - val_accuracy: 0.8526\n",
            "Epoch 16/20\n",
            "1387/1387 [==============================] - 24s 17ms/step - loss: 0.1612 - accuracy: 0.9636 - val_loss: 1.3393 - val_accuracy: 0.8535\n",
            "Epoch 17/20\n",
            "1387/1387 [==============================] - 25s 18ms/step - loss: 0.1393 - accuracy: 0.9687 - val_loss: 1.3631 - val_accuracy: 0.8537\n",
            "Epoch 18/20\n",
            "1387/1387 [==============================] - 24s 18ms/step - loss: 0.1227 - accuracy: 0.9723 - val_loss: 1.3947 - val_accuracy: 0.8541\n",
            "Epoch 19/20\n",
            "1387/1387 [==============================] - 25s 18ms/step - loss: 0.1081 - accuracy: 0.9759 - val_loss: 1.4189 - val_accuracy: 0.8542\n",
            "Epoch 20/20\n",
            "1387/1387 [==============================] - 25s 18ms/step - loss: 0.0936 - accuracy: 0.9792 - val_loss: 1.4552 - val_accuracy: 0.8539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79f45a76ee00>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "uANKB4n3_mWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyH1ucAjjwNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing"
      ],
      "metadata": {
        "id": "Je2ty1KpkYtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/data/Text_summarize/text_summ_model.h5\")"
      ],
      "metadata": {
        "id": "REgBy1MGLpkW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    # Tokenize and pad the input text\n",
        "    text = clean_text(text).split()\n",
        "    text = \" \".join(text[:50])\n",
        "    text_sequence = text_tokenizer.texts_to_sequences([text])\n",
        "    text_sequence = pad_sequences(text_sequence, maxlen=max_text_length, padding='post')\n",
        "\n",
        "    # Initialize the input for the decoder\n",
        "    input_seq = np.zeros((1, max_summary_length))\n",
        "    input_seq[0, 0] = summary_tokenizer.word_index['sos']\n",
        "\n",
        "    # Generate the summary\n",
        "    generated_summary = []\n",
        "\n",
        "    for i in range(1, max_summary_length):\n",
        "        predictions = model.predict([text_sequence, input_seq], verbose=0)\n",
        "        predicted_token_idx = np.argmax(predictions[0, i - 1, :])\n",
        "        if predicted_token_idx == summary_tokenizer.word_index['eos']:\n",
        "            break\n",
        "        generated_summary.append(summary_tokenizer.index_word[predicted_token_idx])\n",
        "        input_seq[0, i] = predicted_token_idx\n",
        "\n",
        "    return ' '.join(generated_summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "RtcAti-YkeE-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted.\"\n",
        "predicted_summary = generate_summary(input_text)\n",
        "print(\"Predicted Summary:\", predicted_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvBnwKD0kkNw",
        "outputId": "b6aa3a6b-9425-4d95-fcab-1c447eec5599"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Summary: received order was wrong\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"I ordered a latte from this cafe, and it was the worst latte I've ever had. The coffee was burnt and bitter, and the milk was frothed to the point where it was just a bunch of bubbles. I tried to drink it, but I couldn't even finish it. It was so bad that I had to throw it away.\"\n",
        "predicted_summary = generate_summary(input_text)\n",
        "print(\"Predicted Summary:\", predicted_summary)"
      ],
      "metadata": {
        "id": "qa4Ci0x1weHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f93909-993f-4855-bc8b-8a7d15e240f4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Summary: mild but still stale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets test with some texts from the real full dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/data/Text_summarize/Reviews.csv\")"
      ],
      "metadata": {
        "id": "XM7VXPI_RjOS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndf = df.sample(10)\n",
        "ndf.reset_index(drop=True, inplace=True)\n",
        "for i in range(7):\n",
        "  txt = ndf['Text'][i]\n",
        "  print(\"======================================\")\n",
        "  print('Actual text : ', clean_text(txt))\n",
        "  print('Real Summary : ', ndf['Summary'][i])\n",
        "  print('Predicted Summary:', generate_summary(txt))\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkAC9QZDkkJ3",
        "outputId": "95461362-cde4-480e-c10b-1117b1f7fc13"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================\n",
            "Actual text :  i just love the senseo coffee maker and pods you practically do not have to be awake to brew a perfect cup of java every morning i can make the fully leaded for myself and the decaf for my husband without dirtying pots finding filters and using anything but our coffee cups and it is perfect every time they are just great for that afternoon cup when you are on the go love my pods \n",
            "Real Summary :  Easy Breezy Coffee\n",
            "Predicted Summary: this is what i like it\n",
            "\n",
            "\n",
            "\n",
            "======================================\n",
            "Actual text :  back in the day when they were still available in the united states crispy m ms were my favorite m ms so you can imagine my excitement when researching crispy m ms online to see if they might make a comeback in the us when i discovered that i could buy them now from a german company on amazon so i placed an order and they arrived well while they are crispy m ms they do not taste as good as i remember them maybe it is my memory or maybe the chocolate is different in germany they tasted more like malted milk balls in an m m she will on a side note if you purchase this item you might experience a delay in shipping like i did because you have to sign for them in order to take delivery they arrived via usps who left me a card to sign i signed the card and my carrier left them two days later \n",
            "Real Summary :  Not entirely what I expected\n",
            "Predicted Summary: not as i am a fantastic price\n",
            "\n",
            "\n",
            "\n",
            "======================================\n",
            "Actual text :  i hate green tea i endured it for my health until i found this tea this one lacks the up front bitterness i have found in so many other green teas it is ethereal delicate in flavor and fragrance i was surprised to find that i loved it and actually missed it when i ran out the secret do not steep too long and drink it before it gets cold delightful cup of tea \n",
            "Real Summary :  Delightfully delicate green tea\n",
            "Predicted Summary: delicious tea it was a bit too\n",
            "\n",
            "\n",
            "\n",
            "======================================\n",
            "Actual text :  i have had this wonderful treat in germany but these guys are selling old and stale stuff and the shipping was over 20 00i have written to them about it and will update this review if they make good on selling outdated candy these guys did make goodand ship another order to me but unfortunately they did not check the product since it too was stale sadly i feel like i cannot change the review \n",
            "Real Summary :  DO NOT BUY THIS FROM THIS SELLER!\n",
            "Predicted Summary: bacon have broken nuts\n",
            "\n",
            "\n",
            "\n",
            "======================================\n",
            "Actual text :  this is not a pack of 12 but of 3 i am very unhappy product is not as described do not order if you expect 12 bones rip off amazon should be ashamed \n",
            "Real Summary :  BEEFEATER PACK OF 12\n",
            "Predicted Summary: too small for the price\n",
            "\n",
            "\n",
            "\n",
            "======================================\n",
            "Actual text :  i ran across this tea while visiting in seattle and its my new favorite must have tea last year i had to cut caffeine and sugar out of my diet and really struggled finding a replacement for coffee w cream and sugar i found safari sunset and was happy until they reformulated it this tea is better than its replacement and cheaper too i love the clovey taste i do not miss coffee at all \n",
            "Real Summary :  Best red tea I've tried\n",
            "Predicted Summary: tastes like liquid tea\n",
            "\n",
            "\n",
            "\n",
            "======================================\n",
            "Actual text :  i agree completely with other reviewers stating that the ideal food for babies up to one year is mother s milk which is mostly fat that being said like most parents we started our son trying solid foods at six months we try to keep his diet balanced never forgetting that his nutritional needs revolve around mother s milk or formula if that is not available as a supplement while keeping the above in mind but still getting our boy up and running with solid foods we found this baby gourmet product is great we try to keep the solids we give our son healthy and we have turned mainly to our own cooking organic vegetables potatoes and meats pureed for him at home this is one of the few processed products we have kept on the menu he loves it and we cannot blame him having given it a little taste ourselves the packaging is great resealable and bpa free the food is a nice treat e g dessert in limited quantities for baby recommended \n",
            "Real Summary :  Great as a treat within a well-balanced baby diet\n",
            "Predicted Summary: my dog loves this stuff\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Bingo !!!😀 It is working really well.</h3>\n",
        "<h5>We have used very limited size of data and very few vocabulary. Even with this limitations the model is generating quite fine summaries. In some cases the model is predicting better than Actual one.</h5>\n",
        "</br></br>\n",
        "\n",
        "<b>Few points should be noted :</b>\n",
        ">* With high config. system and larger set of data, The model can work very efficiently. <br>\n",
        ">* Because of small size vocabulary, the model may not build proper sentences."
      ],
      "metadata": {
        "id": "Lltw2uQUSZDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save(\"/content/drive/MyDrive/data/Text_summarize/text_summ_model.h5\")"
      ],
      "metadata": {
        "id": "rIduQMY6qN-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"text_summ_model.h5\")"
      ],
      "metadata": {
        "id": "eyrizccivQRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}